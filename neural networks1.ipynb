{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "70c34c2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cbe55f4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Sigmoid activation function used in the neural network\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "# Derivative of the sigmoid function used in backpropagation\n",
    "def sigmoid_derivative(x):\n",
    "    return x * (1 - x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7e77dae9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross-entropy loss function used to quantify the difference between prediction and observation\n",
    "def cross_entropy_loss(y_true, y_pred):\n",
    "    epsilon = 1e-15  # to prevent log(0) cases\n",
    "    y_pred = np.clip(y_pred, epsilon, 1 - epsilon)  # clip values to avoid NaNs in logarithms\n",
    "    return -np.sum(y_true * np.log(y_pred)) / len(y_true)\n",
    "\n",
    "# Flatten function to convert images into a 1D array and normalize pixel values\n",
    "def flatten_image(image):\n",
    "    return np.array(image).flatten() / 255.0\n",
    "\n",
    "# Function to load images and labels from a folder\n",
    "def load_images_from_folder(folder):\n",
    "    images = [] #initializing empty list to store images\n",
    "    labels = [] #initializing empty list to store labels\n",
    "\n",
    "    class_folders = [class_folder for class_folder in os.listdir(folder) if os.path.isdir(os.path.join(folder, class_folder))]\n",
    "   #it now contains the names of subdirectories within the specified folder\n",
    "    \n",
    "\n",
    "\n",
    "    for class_folder in class_folders: #loop iterates over each folder in the current class folder\n",
    "        class_path = os.path.join(folder, class_folder) #creates a path to the current class folder\n",
    "\n",
    "        for filename in os.listdir(class_path): #loop iterates over each image in the folder\n",
    "            img_path = os.path.join(class_path, filename)\n",
    "            if img_path.endswith(('.jpg', '.jpeg', '.png')):    #if the image is of this filetype \n",
    "                img = Image.open(img_path)                     #than we convert it into numpy array and append it to the images list\n",
    "                images.append(np.array(img))  \n",
    "                labels.append(class_folder)  #the name of the current class folder is appended to the labels list\n",
    "\n",
    "    return np.array(images), np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "61b38ebb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class representing a simple feedforward neural network\n",
    "class NeuralNetwork:\n",
    "\n",
    "    # The constructor initializes the weights and biases with random values\n",
    "\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "     #input size is the no. of input neurons\n",
    "     #hidden size is the no. of hidden neurons\n",
    "     #output size is the no. of output neurons                                                        \n",
    "\n",
    "                                                            \n",
    "        # Initialize weights and biases\n",
    "        self.weights_input_hidden = np.random.rand(input_size, hidden_size) #randomly initializes weights connecting the input to the hidden layer\n",
    "        self.weights_hidden_output = np.random.rand(hidden_size, output_size)#randomly initializes weights connecting the hidden to the output layer\n",
    "        self.bias_hidden = np.zeros((1, hidden_size)) #bias value of hidden layer initialized to zeroes\n",
    "        self.bias_output = np.zeros((1, output_size)) #bias value of output layer initialized to zeroes\n",
    "\n",
    "    # Method to train the neural network using backpropagation\n",
    "    def train(self, X, y, learning_rate, epochs): #x=input features, y=target labels, epochs=no. of iterations in train dataset\n",
    "        \n",
    "        for epoch in range(epochs):\n",
    "            hidden_input = np.dot(X, self.weights_input_hidden) + self.bias_hidden\n",
    "            hidden_output = sigmoid(hidden_input)\n",
    "\n",
    "            final_input = np.dot(hidden_output, self.weights_hidden_output) + self.bias_output\n",
    "            final_output = sigmoid(final_input)\n",
    "\n",
    "            error = y - final_output\n",
    "            output_delta = error * sigmoid_derivative(final_output)\n",
    "\n",
    "            hidden_layer_error = output_delta.dot(self.weights_hidden_output.T)\n",
    "            hidden_layer_delta = hidden_layer_error * sigmoid_derivative(hidden_output)\n",
    "\n",
    "            # Update weights and biases using gradient descent with cross-entropy loss\n",
    "            self.weights_hidden_output += hidden_output.T.dot(output_delta) * learning_rate\n",
    "            self.bias_output += np.sum(output_delta, axis=0, keepdims=True) * learning_rate\n",
    "            self.weights_input_hidden += X.T.dot(hidden_layer_delta) * learning_rate\n",
    "            self.bias_hidden += np.sum(hidden_layer_delta, axis=0, keepdims=True) * learning_rate\n",
    "\n",
    "            # Print cross-entropy loss for every 100 epochs\n",
    "            if epoch % 100 == 0:\n",
    "                ce_loss = cross_entropy_loss(y, final_output)\n",
    "                print(f\"Epoch {epoch}, Cross-Entropy Loss: {ce_loss}\")\n",
    "\n",
    "    # Method to make predictions using trained neural network\n",
    "    def predict(self, X): #x is input data for which predictions are made\n",
    "\n",
    "        hidden_input = np.dot(X, self.weights_input_hidden) + self.bias_hidden\n",
    "        hidden_output = sigmoid(hidden_input)\n",
    "\n",
    "        final_input = np.dot(hidden_output, self.weights_hidden_output) + self.bias_output\n",
    "        final_output = sigmoid(final_input)\n",
    "\n",
    "        return np.argmax(final_output, axis=1).reshape(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "673872ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Cross-Entropy Loss: 5.3392975276460515\n",
      "Epoch 100, Cross-Entropy Loss: 4.5123280112413516e-14\n",
      "Epoch 200, Cross-Entropy Loss: 4.5123280112413516e-14\n",
      "Epoch 300, Cross-Entropy Loss: 4.5123280112413516e-14\n",
      "Epoch 400, Cross-Entropy Loss: 4.5123280112413516e-14\n",
      "Epoch 500, Cross-Entropy Loss: 4.5123280112413516e-14\n",
      "Epoch 600, Cross-Entropy Loss: 4.5123280112413516e-14\n",
      "Epoch 700, Cross-Entropy Loss: 4.5123280112413516e-14\n",
      "Epoch 800, Cross-Entropy Loss: 4.5123280112413516e-14\n",
      "Epoch 900, Cross-Entropy Loss: 4.5123280112413516e-14\n",
      "Unique values in val_labels: [0 1 2 3 4 5 6 7 8 9]\n",
      "Unique values in val_predicted_labels: [0]\n",
      "Validation Accuracy: 0.10375\n",
      "Test Accuracy: 0.1\n"
     ]
    }
   ],
   "source": [
    "# Main section\n",
    "if __name__ == \"__main__\":\n",
    "    train_folder_path = \"/Users/rohanshenoy/Downloads/train\"\n",
    "    test_folder_path = \"/Users/rohanshenoy/Downloads/test\"\n",
    "\n",
    "    # Load training images and labels\n",
    "    train_images, train_labels = load_images_from_folder(train_folder_path)\n",
    "\n",
    "    # Load testing images and labels\n",
    "    test_images, test_labels = load_images_from_folder(test_folder_path)\n",
    "\n",
    "    # Encode labels using scikit-learn LabelEncoder\n",
    "    label_encoder = LabelEncoder()\n",
    "    encoded_train_labels = label_encoder.fit_transform(train_labels)\n",
    "    encoded_test_labels = label_encoder.transform(test_labels)\n",
    "\n",
    "    # Flatten the images and normalize them\n",
    "    train_images = np.array([flatten_image(img) for img in train_images])\n",
    "    test_images = np.array([flatten_image(img) for img in test_images])\n",
    "\n",
    "    # Ensure labels have the correct shape\n",
    "    encoded_train_labels = encoded_train_labels.reshape(-1, 1)  # Reshape to (num_samples, 1)\n",
    "    encoded_test_labels = encoded_test_labels.flatten()\n",
    "\n",
    "    # Split the data into training and testing sets\n",
    "    train_images, val_images, train_labels, val_labels = train_test_split(train_images, encoded_train_labels, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Initialize and train the neural network\n",
    "    neural_net = NeuralNetwork(input_size=len(flatten_image(train_images[0])), hidden_size=4, output_size=len(np.unique(encoded_train_labels)))\n",
    "    neural_net.train(train_images, train_labels, learning_rate=0.1, epochs=1000)\n",
    "\n",
    "    # Make predictions on the validation set\n",
    "    val_predictions = neural_net.predict(val_images)\n",
    "    val_predicted_labels = np.round(val_predictions)\n",
    "\n",
    "    print(\"Unique values in val_labels:\", np.unique(val_labels))\n",
    "    print(\"Unique values in val_predicted_labels:\", np.unique(val_predicted_labels))\n",
    "\n",
    "    # Calculate accuracy on the validation set\n",
    "    val_accuracy = accuracy_score(val_labels, val_predicted_labels)\n",
    "    print(f\"Validation Accuracy: {val_accuracy}\")\n",
    "\n",
    "    # Make predictions on the test set\n",
    "    test_predictions = neural_net.predict(test_images)\n",
    "    test_predicted_labels = np.round(test_predictions)\n",
    "\n",
    "    # Calculate accuracy on the test set\n",
    "    test_accuracy = accuracy_score(encoded_test_labels, test_predicted_labels)\n",
    "    print(f\"Test Accuracy: {test_accuracy}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
